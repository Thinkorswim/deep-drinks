{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from helpers import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3347 recipes in the database.\n"
     ]
    }
   ],
   "source": [
    "data = [ \n",
    "    'data/liquor.json',\n",
    "    'data/social_cocktail.json',\n",
    "    'data/serious_eats.json',\n",
    "    'data/live_in_style.json',\n",
    "    'data/all_recipes.json'\n",
    "]\n",
    "\n",
    "descriptions, ingredients, names = [], [], []\n",
    "\n",
    "for d in data:\n",
    "    descriptions += load_data(d, field='description')\n",
    "    ingredients += load_data(d, field='ingredients')\n",
    "    names += load_data(d, field='name')\n",
    "\n",
    "assert len(descriptions) == len(ingredients)\n",
    "\n",
    "recipes = [x + ' # ' + y for x, y in zip(ingredients, descriptions)]    \n",
    "print('There are {} recipes in the database.'.format(len(recipes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "T = [clean_string(x) for x in ingredients]\n",
    "T = sentences_to_words(T)\n",
    "\n",
    "N = [clean_string(x) for x in names]\n",
    "N = [x.split() for x in N]\n",
    "\n",
    "rIngr = []\n",
    "rNames = []\n",
    "\n",
    "\n",
    "for i,t in enumerate(T):\n",
    "    if len(t) <= 30 and len(N[i]) <= 8:\n",
    "        rIngr = rIngr + [t]\n",
    "        rNames = rNames + [N[i]]\n",
    "    \n",
    "rIngr = [np.append(x, [\"null\"]*(30-len(x))) for x in rIngr]\n",
    "rNames = [np.append(x, [\"null\"]*(8-len(x))) for x in rNames]\n",
    "\n",
    "rIngr = np.array(rIngr)\n",
    "rNames = np.array(rNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3292, 30)\n",
      "(3292, 8)\n"
     ]
    }
   ],
   "source": [
    "print(rIngr.shape)\n",
    "print(rNames.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fresh' 'juice' 'simple' 'leaves' 'lemon' 'syrup' 'null' 'null' 'null'\n",
      " 'null' 'null' 'null' 'null' 'null' 'null' 'null' 'null' 'null' 'null'\n",
      " 'null' 'null' 'null' 'null' 'null' 'null' 'null' 'null' 'null' 'null'\n",
      " 'null']\n",
      "['south' 'side' 'null' 'null' 'null' 'null' 'null' 'null']\n"
     ]
    }
   ],
   "source": [
    "print(rIngr[123])\n",
    "print(rNames[123])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Martin\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "flat = np.append(rNames.flatten(),rIngr.flatten())\n",
    "label_encoder.fit(flat)\n",
    "k = label_encoder.transform([[x] for x in list(set(flat))])\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "onehot_encoder.fit(k.reshape(-1,1))\n",
    "\n",
    "\n",
    "fIngr = []\n",
    "fNames = []\n",
    "\n",
    "for i,_ in enumerate(rNames):\n",
    "    fIngr += [np.array(onehot_encoder.transform(label_encoder.transform(rIngr[i]).reshape(-1,1))).flatten()]\n",
    "    fNames += [np.array(onehot_encoder.transform(label_encoder.transform(rNames[i]).reshape(-1,1))).flatten()]\n",
    "    \n",
    "X = np.array(fIngr)\n",
    "y = np.array(fNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3127, 124560) (3127, 33216) (165, 124560) (165, 33216)\n"
     ]
    }
   ],
   "source": [
    "N = X.shape[0]\n",
    "X_train, y_train = X[:int(N*0.95)], y[:int(N*0.95)]\n",
    "X_val, y_val = X[int(N*0.95):], y[int(N*0.95):]\n",
    "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM, GRU\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               63775232  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 33216)             17039808  \n",
      "=================================================================\n",
      "Total params: 80,815,040\n",
      "Trainable params: 80,815,040\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, input_dim=X.shape[1], activation='relu'))\n",
    "# model.add(Dense(256, input_dim=X.shape[1], activation='relu'))\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "# model.add(Dense(64, activation='relu'))\n",
    "\n",
    "# model.add(GRU(512, input_shape=(X.shape[1], X.shape[2]), activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(GRU(128, input_shape=(X.shape[1], X.shape[2]), activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(Dense(33216, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', metrics=['categorical_accuracy'], optimizer='adam')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3127 samples, validate on 165 samples\n",
      "Epoch 1/10\n",
      "3127/3127 [==============================] - 229s 73ms/step - loss: 17.7178 - categorical_accuracy: 0.1976 - val_loss: 45.9632 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "3127/3127 [==============================] - 245s 78ms/step - loss: 17.6572 - categorical_accuracy: 0.2069 - val_loss: 45.9557 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "3127/3127 [==============================] - 241s 77ms/step - loss: 17.5902 - categorical_accuracy: 0.2143 - val_loss: 45.8997 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "3127/3127 [==============================] - 251s 80ms/step - loss: 17.5475 - categorical_accuracy: 0.2165 - val_loss: 46.2545 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "3127/3127 [==============================] - 269s 86ms/step - loss: 17.5171 - categorical_accuracy: 0.2245 - val_loss: 46.1039 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "3127/3127 [==============================] - 303s 97ms/step - loss: 17.4859 - categorical_accuracy: 0.2242 - val_loss: 46.1712 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "3127/3127 [==============================] - 285s 91ms/step - loss: 17.4537 - categorical_accuracy: 0.2264 - val_loss: 46.3647 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "3127/3127 [==============================] - 303s 97ms/step - loss: 17.4194 - categorical_accuracy: 0.2350 - val_loss: 46.4746 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "3127/3127 [==============================] - 357s 114ms/step - loss: 17.3932 - categorical_accuracy: 0.2296 - val_loss: 46.3048 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "3127/3127 [==============================] - 287s 92ms/step - loss: 17.3910 - categorical_accuracy: 0.2341 - val_loss: 46.5775 - val_categorical_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23e8efe3278>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vodka' 'blanc' 'plymouth' 'absolut' 'lillet' 'null' 'null' 'null' 'null'\n",
      " 'null' 'null' 'null' 'null' 'null' 'null' 'null' 'null' 'null' 'null'\n",
      " 'null' 'null' 'null' 'null' 'null' 'null' 'null' 'null' 'null' 'null'\n",
      " 'null']\n",
      "['vesper' 'null' 'null' 'null' 'null' 'null' 'null' 'null']\n",
      "['blue' 'martini' 'null' 'null' 'null' 'null' 'null' 'null']\n"
     ]
    }
   ],
   "source": [
    "ent = 100\n",
    "\n",
    "predict = X_val[ent]\n",
    "p = model.predict(x=np.array([predict]),batch_size=batch_size)\n",
    "p = p.reshape(8,4152)\n",
    "b = np.zeros_like(p)\n",
    "b[np.arange(len(p)), p.argmax(1)] = 1\n",
    "decoded = b.dot(onehot_encoder.active_features_).astype(int)\n",
    "result = label_encoder.inverse_transform(decoded)\n",
    "\n",
    "\n",
    "print(rIngr[ent])\n",
    "print(rNames[ent])\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_file = 'm30.json'\n",
    "weights_file = 'w30.h5'\n",
    "\n",
    "def save_model_to_json(model, model_file, weights_file):\n",
    "    model_json = model.to_json()\n",
    "    with open(model_file, \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    model.save_weights(weights_file)\n",
    "    \n",
    "save_model_to_json(model, model_file, weights_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
